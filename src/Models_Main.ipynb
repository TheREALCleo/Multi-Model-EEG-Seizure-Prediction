{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c66112aa-691c-4ff4-a60d-82c758d49bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5d9e82-3ef4-48f1-a147-fcc6e8723c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 79\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m'\u001b[39m: y_test,\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m: y_pred,\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_proba\u001b[39m\u001b[38;5;124m'\u001b[39m: y_proba,\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportances\u001b[39m\u001b[38;5;124m'\u001b[39m: rf\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m     76\u001b[0m     }\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Parallel processing of folds\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mN_SPLITS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_JOBS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Aggregate results\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[1;32mD:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix,\n",
    "                             classification_report, roc_curve)\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Load features\n",
    "df = pd.read_csv('D:\\\\MOOC.fi\\\\Jupyter\\\\EEG\\\\Dataset\\\\timefeature_data.csv').dropna()\n",
    "\n",
    "# Configuration\n",
    "N_SPLITS = 5\n",
    "N_JOBS = -1\n",
    "N_ESTIMATORS = 1000\n",
    "RANDOM_STATE = None\n",
    "\n",
    "# Prepare data\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "features = X.columns.tolist()\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Initialize metrics storage\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1': [],\n",
    "    'roc_auc': []\n",
    "}\n",
    "\n",
    "# Storage for final aggregation\n",
    "all_y_test = []\n",
    "all_y_pred = []\n",
    "all_y_proba = []\n",
    "feature_importances = []\n",
    "\n",
    "def process_fold(train_idx, test_idx, X, y):\n",
    "    \"\"\"Process one fold with full CPU utilization\"\"\"\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Class weights\n",
    "    classes = np.unique(y_train)\n",
    "    weights = class_weight.compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "    weight_dict = {cls: w for cls, w in zip(classes, weights)}\n",
    "    \n",
    "    # Model training\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        max_depth=15,\n",
    "        class_weight=weight_dict,\n",
    "        n_jobs=N_JOBS,\n",
    "        verbose=2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        criterion='gini'\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return {\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'y_proba': y_proba,\n",
    "        'importances': rf.feature_importances_\n",
    "    }\n",
    "\n",
    "# Parallel processing of folds\n",
    "results = Parallel(n_jobs=min(N_SPLITS, N_JOBS), verbose=10)(\n",
    "    delayed(process_fold)(train_idx, test_idx, X, y)\n",
    "    for train_idx, test_idx in skf.split(X, y)\n",
    ")\n",
    "\n",
    "# Aggregate results\n",
    "for result in results:\n",
    "    all_y_test.extend(result['y_test'])\n",
    "    all_y_pred.extend(result['y_pred'])\n",
    "    all_y_proba.extend(result['y_proba'])\n",
    "    feature_importances.append(result['importances'])\n",
    "    \n",
    "    # Calculate fold metrics\n",
    "    metrics['accuracy'].append(accuracy_score(result['y_test'], result['y_pred']))\n",
    "    metrics['precision'].append(precision_score(result['y_test'], result['y_pred']))\n",
    "    metrics['recall'].append(recall_score(result['y_test'], result['y_pred']))\n",
    "    metrics['f1'].append(f1_score(result['y_test'], result['y_pred']))\n",
    "    metrics['roc_auc'].append(roc_auc_score(result['y_test'], result['y_proba']))\n",
    "\n",
    "# Calculate average feature importances\n",
    "mean_importances = np.mean(feature_importances, axis=0)\n",
    "std_importances = np.std(feature_importances, axis=0)\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(metrics['accuracy']):.4f} (±{np.std(metrics['accuracy']):.4f})\")\n",
    "print(f\"Average Precision: {np.mean(metrics['precision']):.4f} (±{np.std(metrics['precision']):.4f})\")\n",
    "print(f\"Average Recall: {np.mean(metrics['recall']):.4f} (±{np.std(metrics['recall']):.4f})\")\n",
    "print(f\"Average F1: {np.mean(metrics['f1']):.4f} (±{np.std(metrics['f1']):.4f})\")\n",
    "print(f\"Average ROC AUC: {np.mean(metrics['roc_auc']):.4f} (±{np.std(metrics['roc_auc']):.4f})\")\n",
    "\n",
    "# Final evaluation on all predictions\n",
    "print(\"\\nAggregated Evaluation:\")\n",
    "print(classification_report(all_y_test, all_y_pred, target_names=['Normal', 'Event']))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(all_y_test, all_y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=',d', cmap='Blues',\n",
    "            xticklabels=['Normal', 'Event'],\n",
    "            yticklabels=['Normal', 'Event'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Aggregated Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(all_y_test, all_y_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "         label=f'ROC Curve (AUC = {roc_auc_score(all_y_test, all_y_proba):.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Aggregated ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "indices = np.argsort(mean_importances)[-20:]\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Top 20 Feature Importances (Mean ± SD)')\n",
    "plt.barh(range(len(indices)), mean_importances[indices], xerr=std_importances[indices],\n",
    "         align='center', color='teal', ecolor='black')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Mean Importance Score')\n",
    "plt.grid(axis='x', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a5471-4d06-4642-a998-5032747009eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b321125-9377-43f4-b8d0-273a6518ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('D:\\\\MOOC.fi\\\\Jupyter\\\\EEG\\\\Dataset\\\\timefeature_data.csv')\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Split into train-test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Create processing pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Crucial for KNN performance\n",
    "    ('knn', KNeighborsClassifier(n_jobs=-1))  # Utilize all CPU cores\n",
    "])\n",
    "\n",
    "# Hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': list(range(1, 10, 2)),  # Test various neighborhood sizes\n",
    "    'knn__weights': ['uniform', 'distance'],  # Test weighting schemes\n",
    "    'knn__metric': ['euclidean', 'manhattan', 'minkowski']  # Different distance metrics\n",
    "}\n",
    "\n",
    "# Configure grid search with stratified k-fold\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1  # Utilize all CPU cores for parallel processing\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Test set evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"=== Best Model Test Set Performance ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Cross-validated metrics\n",
    "print(\"\\n=== Cross-Validated Metrics ===\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "cv_results = cross_validate(\n",
    "    best_model,\n",
    "    X, y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"Average Accuracy: {cv_results['test_accuracy'].mean():.4f} (±{cv_results['test_accuracy'].std():.4f})\")\n",
    "print(f\"Average Precision: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "print(f\"Average Recall: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "print(f\"Average F1-Score: {cv_results['test_f1_macro'].mean():.4f}\")\n",
    "\n",
    "# Display best parameters\n",
    "print(\"\\n=== Optimal Hyperparameters ===\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_proba = best_model.predict_proba(X_test)\n",
    "n_classes = len(best_model.classes_)\n",
    "\n",
    "# For binary classification\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "# Enhanced Confusion Matrix Visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_model,\n",
    "    X_test, y_test,\n",
    "    display_labels=best_model.classes_,\n",
    "    cmap=plt.cm.Blues,\n",
    "    normalize='true'\n",
    ")\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2b1f2-eb47-4bfd-816c-cdfa4e402fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3cb4c-b3c9-4b09-9330-36cf19e32667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report, \n",
    "                             roc_curve, auc, roc_auc_score)\n",
    "\n",
    "# -------------------------------\n",
    "# Load your EEG time-domain features\n",
    "# -------------------------------\n",
    "# Assumes 'eeg_features.csv' has feature columns and a 'label' column.\n",
    "data = pd.read_csv('D:\\\\MOOC.fi\\\\Jupyter\\\\EEG\\\\Dataset\\\\timefeature_data.csv')\n",
    "\n",
    "# Separate features and target labels\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# -------------------------------\n",
    "# Split data into training and testing sets\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Set up Grid Search with K-Fold Cross Validation\n",
    "# -------------------------------\n",
    "# SVM with probability=True to enable ROC curve plotting\n",
    "svc = SVC(probability=True, random_state=0)\n",
    "\n",
    "# Define parameter grid: try various kernels and optionally adjust C and gamma.\n",
    "param_grid = {\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'C': [100],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "# Using 5-fold cross validation\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters from GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate the Best Model on Test Set\n",
    "# -------------------------------\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nTest Set Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# -------------------------------\n",
    "# Plot Confusion Matrix using Seaborn\n",
    "# -------------------------------\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14620c04-3d6e-4f2a-a8f4-61bbcf32de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2f628-d34d-4e1a-9728-cc33840b5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report,\n",
    "                             ConfusionMatrixDisplay)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('D:\\\\MOOC.fi\\\\Jupyter\\\\EEG\\\\Dataset\\\\timefeature_data.csv')\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Advanced preprocessing\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Calculate class weights\n",
    "classes = np.unique(y)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Custom LightGBM dataset creation\n",
    "train_data = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, free_raw_data=False)\n",
    "\n",
    "# Advanced parameter grid\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt', 'dart'],  # Different boosting types\n",
    "    'num_leaves': [63],        # Control tree complexity\n",
    "    'max_depth': [ 7, 15],           # Limit tree depth\n",
    "    'learning_rate': [ 0.05],\n",
    "    'n_estimators': [200],\n",
    "    'subsample': [0.8, 1.0],            # Stochastic gradient boosting\n",
    "    'colsample_bytree': [0.8, 1.0],     # Feature fraction\n",
    "    'reg_alpha': [0.1],           # L1 regularization\n",
    "    'reg_lambda': [0.1],          # L2 regularization\n",
    "    'min_child_samples': [20],      # Prevent overfitting\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'device': ['gpu']\n",
    "}\n",
    "\n",
    "# Advanced model configuration\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective='binary',  # Change for multiclass\n",
    "    metric='binary_logloss',\n",
    "    boosting_type='gbdt',\n",
    "    importance_type='gain',\n",
    "    device='gpu',\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# Nested cross-validation\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Hyperparameter optimization\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=inner_cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Advanced evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"=== Advanced Metrics ===\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    return y_proba\n",
    "\n",
    "# Feature Importance Visualization\n",
    "def plot_feature_importance(model, features):\n",
    "    importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(importance['Feature'][:20], importance['Importance'][:20])\n",
    "    plt.title('Top 20 Feature Importance')\n",
    "    plt.xlabel('Gain Importance')\n",
    "    plt.show()\n",
    "\n",
    "# SHAP Value Analysis\n",
    "def shap_analysis(model, X):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    \n",
    "    # If binary classification, shap_values will be a list with two arrays\n",
    "    if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "        shap_values = shap_values[1]  # Use the SHAP values for the positive class\n",
    "    \n",
    "    # SHAP Feature Importance (Bar Plot)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False)\n",
    "    plt.title('SHAP Feature Importance')\n",
    "    plt.show()\n",
    "    \n",
    "    # SHAP Value Distribution (Summary Plot)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X, show=False)\n",
    "    plt.title('SHAP Value Distribution')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Learning Curve Analysis\n",
    "def plot_learning_curve(model, X, y):\n",
    "    results = model.evals_result_\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(results['training']['binary_logloss'], label='Train')\n",
    "    plt.plot(results['validation']['binary_logloss'], label='Validation')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Log Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Execute evaluation\n",
    "y_proba = evaluate_model(best_model, X_test, y_test)\n",
    "plot_feature_importance(best_model, X.columns)\n",
    "shap_analysis(best_model, X_test)\n",
    "plot_learning_curve(best_model, X_train, y_train)\n",
    "\n",
    "# Cross-validated metrics\n",
    "print(\"\\n=== Cross-Validated Metrics ===\")\n",
    "cv_results = cross_validate(\n",
    "    best_model,\n",
    "    X, y,\n",
    "    cv=outer_cv,\n",
    "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc'],\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"Average Validation Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
    "print(f\"Average Validation ROC AUC: {np.mean(cv_results['test_roc_auc']):.4f}\")\n",
    "print(f\"Average Training Accuracy: {np.mean(cv_results['train_accuracy']):.4f}\")\n",
    "print(\"\\nTraining vs Validation Scores:\")\n",
    "print(pd.DataFrame({\n",
    "    'Fold': range(1, 6),\n",
    "    'Train Accuracy': cv_results['train_accuracy'],\n",
    "    'Val Accuracy': cv_results['test_accuracy'],\n",
    "    'Train ROC AUC': cv_results['train_roc_auc'],\n",
    "    'Val ROC AUC': cv_results['test_roc_auc']\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2d3d7-4983-4739-a5a5-aa37015dab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36933b9-b6da-4d37-98f2-ed11b12fd35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report,\n",
    "                             ConfusionMatrixDisplay, roc_curve, auc)\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('D:\\\\MOOC.fi\\\\Jupyter\\\\EEG\\\\Dataset\\\\timefeature_data.csv')\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Advanced train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Advanced parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_iter': [100, 300],\n",
    "    'max_depth': [3, 7, None],\n",
    "    'max_leaf_nodes': [15, 31],\n",
    "    'min_samples_leaf': [20, 50],\n",
    "    'l2_regularization': [0.0, 0.1],\n",
    "    'max_bins': [128],\n",
    "    'scoring': ['loss', 'accuracy'],\n",
    "    'early_stopping': [True]\n",
    "}\n",
    "\n",
    "# Advanced model configuration\n",
    "model = HistGradientBoostingClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_iter_no_change=10,\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "# Nested cross-validation setup\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Hyperparameter optimization\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=inner_cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Advanced evaluation metrics\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"=== Advanced Metrics ===\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return y_proba\n",
    "\n",
    "\n",
    "# Learning Curve Analysis\n",
    "def plot_learning_curve(model):\n",
    "    train_scores = model.train_score_\n",
    "    validation_scores = model.validation_score_\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_scores, label='Train')\n",
    "    plt.plot(validation_scores, label='Validation')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Execute evaluation\n",
    "y_proba = evaluate_model(best_model, X_test, y_test)\n",
    "plot_learning_curve(best_model)\n",
    "\n",
    "# Cross-validated metrics\n",
    "print(\"\\n=== Cross-Validated Metrics ===\")\n",
    "cv_results = cross_validate(\n",
    "    best_model,\n",
    "    X, y,\n",
    "    cv=outer_cv,\n",
    "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc'],\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"Average Validation Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
    "print(f\"Average Validation ROC AUC: {np.mean(cv_results['test_roc_auc']):.4f}\")\n",
    "print(f\"Average Training Accuracy: {np.mean(cv_results['train_accuracy']):.4f}\")\n",
    "print(\"\\nTraining vs Validation Scores:\")\n",
    "print(pd.DataFrame({\n",
    "    'Fold': range(1, 6),\n",
    "    'Train Accuracy': cv_results['train_accuracy'],\n",
    "    'Val Accuracy': cv_results['test_accuracy'],\n",
    "    'Train ROC AUC': cv_results['train_roc_auc'],\n",
    "    'Val ROC AUC': cv_results['test_roc_auc']\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466e3d5-6c67-420b-9c37-16e7b9ab2614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b88fd-c136-4190-8b14-3a6e7f66b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf3485-6f33-4747-adfb-4bcaacd4093e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 660, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1682, in fit\n    self._Booster = train(\n                    ^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\training.py\", line 184, in train\n    if cb_container.after_iteration(bst, i, dtrain, evals):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\callback.py\", line 267, in after_iteration\n    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\callback.py\", line 267, in <genexpr>\n    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\callback.py\", line 463, in after_iteration\n    raise ValueError(msg)\nValueError: Must have at least 1 validation dataset for early stopping.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 177\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# Cross-validated metrics\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Cross-Validated Metrics ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 177\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision_macro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall_macro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1_macro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroc_auc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    184\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Validation ROC AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_roc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mD:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:431\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    411\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    412\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    413\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    429\u001b[0m )\n\u001b[1;32m--> 431\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mD:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    516\u001b[0m     )\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 660, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1682, in fit\n    self._Booster = train(\n                    ^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\training.py\", line 184, in train\n    if cb_container.after_iteration(bst, i, dtrain, evals):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\callback.py\", line 267, in after_iteration\n    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\callback.py\", line 267, in <genexpr>\n    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\MOOC.fi\\Jupyter\\env\\Lib\\site-packages\\xgboost\\callback.py\", line 463, in after_iteration\n    raise ValueError(msg)\nValueError: Must have at least 1 validation dataset for early stopping.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report,\n",
    "                             ConfusionMatrixDisplay, roc_curve, auc)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Custom transformer to convert array back to DataFrame with feature names\n",
    "class DataFrameTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # If X is already a DataFrame, simply return it.\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X\n",
    "        return pd.DataFrame(X, columns=self.columns)\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('D:\\\\MOOC.fi\\\\Jupyter\\\\EEG\\\\Dataset\\\\timefeature_data.csv')\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Advanced parameter grid\n",
    "param_grid = {\n",
    "    'xgb__learning_rate': [0.01, 0.1],\n",
    "    'xgb__max_depth': [3, 6, 9], \n",
    "    'xgb__subsample': [0.6, 0.8],\n",
    "    'xgb__colsample_bytree': [0.6, 0.8], \n",
    "    'xgb__gamma': [0, 0.1],\n",
    "    'xgb__reg_alpha': [0, 0.1],\n",
    "    'xgb__reg_lambda': [0, 0.1],\n",
    "    'xgb__scale_pos_weight': [1, None],  # For class imbalance\n",
    "    'xgb__tree_method': ['hist'],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "# Create pipeline with scaling, DataFrame conversion, and XGBoost\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('to_df', DataFrameTransformer(columns=X.columns)),\n",
    "    ('xgb', xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=1000,  # Use early stopping\n",
    "        early_stopping_rounds=50,\n",
    "        random_state=42,\n",
    "        tree_method='hist',\n",
    "        device = 'cuda', # GPU-accelerated histogram-based algorithm\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Advanced cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Hyperparameter search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit grid search with eval_set for early stopping on the XGBoost estimator\n",
    "grid_search.fit(X_train, y_train, xgb__eval_set=[(X_test, y_test)])\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Advanced evaluation function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"=== Advanced Metrics ===\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return y_proba\n",
    "\n",
    "# Feature Importance Visualization\n",
    "def plot_feature_importance(model):\n",
    "    xgb_feat_imp = model.named_steps['xgb'].feature_importances_\n",
    "    importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': xgb_feat_imp\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(importance['Feature'][:20], importance['Importance'][:20])\n",
    "    plt.title('Top 20 XGBoost Feature Importance (Gain)')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "# SHAP Explainability\n",
    "def shap_analysis(model, X):\n",
    "    # Transform data with scaler and DataFrameTransformer if available\n",
    "    if 'to_df' in model.named_steps:\n",
    "        X_processed = model.named_steps['to_df'].transform(model.named_steps['scaler'].transform(X))\n",
    "    else:\n",
    "        X_processed = X\n",
    "    explainer = shap.TreeExplainer(model.named_steps['xgb'])\n",
    "    shap_values = explainer.shap_values(X_processed)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False)\n",
    "    plt.title('SHAP Feature Importance')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X, show=False)\n",
    "    plt.title('SHAP Value Distribution')\n",
    "    plt.show()\n",
    "\n",
    "# Learning Curve Plot\n",
    "def plot_learning_curve(model):\n",
    "    results = model.named_steps['xgb'].evals_result()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(results['validation_0']['logloss'], label='Validation Logloss')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Log Loss')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Execute evaluation\n",
    "y_proba = evaluate_model(best_model, X_test, y_test)\n",
    "plot_feature_importance(best_model)\n",
    "shap_analysis(best_model, X_test)\n",
    "plot_learning_curve(best_model)\n",
    "\n",
    "# Cross-validated metrics\n",
    "print(\"\\n=== Cross-Validated Metrics ===\")\n",
    "cv_results = cross_validate(\n",
    "    best_model,\n",
    "    X, y,\n",
    "    cv=cv,\n",
    "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc'],\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"Average Validation Accuracy: {np.mean(cv_results['test_accuracy']):.4f}\")\n",
    "print(f\"Average Validation ROC AUC: {np.mean(cv_results['test_roc_auc']):.4f}\")\n",
    "print(\"\\nTraining vs Validation Scores:\")\n",
    "print(pd.DataFrame({\n",
    "    'Fold': range(1, 6),\n",
    "    'Train Accuracy': cv_results['train_accuracy'],\n",
    "    'Val Accuracy': cv_results['test_accuracy'],\n",
    "    'Train ROC AUC': cv_results['train_roc_auc'],\n",
    "    'Val ROC AUC': cv_results['test_roc_auc']\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d94e58-cfd9-48ed-b727-0bd602543952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52f480-a494-4827-9c12-48be2e5b568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ea125-9828-4b29-8d57-aa0bb8adbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e62374-8315-4ec1-8255-e42e97dc7554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Loss: 0.0254 | Val Accuracy: 84.10%\n",
      "Epoch 2/20 | Loss: 0.0239 | Val Accuracy: 84.77%\n",
      "Epoch 3/20 | Loss: 0.0235 | Val Accuracy: 85.23%\n",
      "Epoch 4/20 | Loss: 0.0232 | Val Accuracy: 85.14%\n",
      "Epoch 5/20 | Loss: 0.0230 | Val Accuracy: 85.79%\n",
      "Epoch 6/20 | Loss: 0.0228 | Val Accuracy: 85.82%\n",
      "Epoch 7/20 | Loss: 0.0227 | Val Accuracy: 85.81%\n",
      "Epoch 8/20 | Loss: 0.0226 | Val Accuracy: 86.09%\n",
      "Epoch 9/20 | Loss: 0.0225 | Val Accuracy: 86.24%\n",
      "Epoch 10/20 | Loss: 0.0224 | Val Accuracy: 86.19%\n",
      "Epoch 11/20 | Loss: 0.0223 | Val Accuracy: 86.32%\n",
      "Epoch 12/20 | Loss: 0.0222 | Val Accuracy: 86.35%\n",
      "Epoch 13/20 | Loss: 0.0222 | Val Accuracy: 86.14%\n",
      "Epoch 14/20 | Loss: 0.0221 | Val Accuracy: 86.37%\n",
      "Epoch 15/20 | Loss: 0.0221 | Val Accuracy: 86.63%\n",
      "Epoch 16/20 | Loss: 0.0220 | Val Accuracy: 86.59%\n",
      "Epoch 17/20 | Loss: 0.0220 | Val Accuracy: 86.54%\n",
      "Epoch 18/20 | Loss: 0.0220 | Val Accuracy: 86.31%\n",
      "Epoch 19/20 | Loss: 0.0219 | Val Accuracy: 86.60%\n",
      "Epoch 20/20 | Loss: 0.0219 | Val Accuracy: 86.70%\n",
      "Best Validation Accuracy: 86.70%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load and preprocess data (unchanged)\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Total features: {len(df.columns)-1}\")\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Focal Loss Implementation\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = self.bce(inputs, targets)\n",
    "        probs = torch.sigmoid(inputs)\n",
    "        p_t = targets * probs + (1 - targets) * (1 - probs)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "# Updated Neural Network Architecture with BatchNorm\n",
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=23):\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.output = nn.Linear(64, 1)  # Output raw logits\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return self.output(x)\n",
    "\n",
    "# Modified training function with learning rate scheduler and early stopping\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=200):\n",
    "    model.to(device)\n",
    "    scaler = GradScaler()\n",
    "    best_accuracy = 0.0\n",
    "    patience = 10  # Number of epochs to wait before early stopping\n",
    "    trigger_times = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True).float().view(-1, 1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                predicted = (probabilities >= 0.5).float().squeeze()\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.4f} | Val Accuracy: {accuracy:.2f}%')\n",
    "        \n",
    "        # Step the scheduler based on validation accuracy\n",
    "        scheduler.step(accuracy)\n",
    "        \n",
    "        # Early stopping (optional)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    \n",
    "    print(f'Best Validation Accuracy: {best_accuracy:.2f}%')\n",
    "\n",
    "# Main execution with optimized data loading and model training\n",
    "if __name__ == '__main__':\n",
    "    # Load data\n",
    "    X_train, X_test, y_train, y_test = load_data('D:\\\\MOOC.fi\\\\Jupyter\\\\EEG\\\\Dataset\\\\chbmit_preprocessed_data.csv')\n",
    "    \n",
    "    # Convert to CPU tensors first\n",
    "    train_features = torch.tensor(X_train, dtype=torch.float32)\n",
    "    train_labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "    test_features = torch.tensor(X_test, dtype=torch.float32)\n",
    "    test_labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "    \n",
    "    # Create DataLoaders with pin_memory for faster GPU transfer\n",
    "    train_dataset = TensorDataset(train_features, train_labels)\n",
    "    test_dataset = TensorDataset(test_features, test_labels)\n",
    "\n",
    "    batch_size = 1024\n",
    "    num_workers = 4  # Adjust based on your system\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=True,\n",
    "                              persistent_workers=False)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             num_workers=num_workers,\n",
    "                             pin_memory=True,\n",
    "                             persistent_workers=False)\n",
    "    \n",
    "    # Initialize model and optimizer\n",
    "    model = EEGClassifier(input_dim=train_features.shape[1])\n",
    "    \n",
    "    # Toggle between BCEWithLogitsLoss and FocalLoss\n",
    "    use_focal_loss = True\n",
    "    if use_focal_loss:\n",
    "        criterion = FocalLoss(alpha=0.25, gamma=2)\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    \n",
    "    # Initialize learning rate scheduler based on validation accuracy\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99970bb8-0c74-4cce-93b3-d60369e409a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, \n",
    "                             roc_auc_score, roc_curve, precision_recall_curve,\n",
    "                             average_precision_score)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds and device\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Enhanced Data Loader with optimized memory management\n",
    "def load_data(file_path, test_size=0.2):\n",
    "    # Load data in chunks to handle large dataset\n",
    "    chunk_size = 100000\n",
    "    chunks = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "    \n",
    "    X_list, y_list = [], []\n",
    "    for chunk in chunks:\n",
    "        X_list.append(chunk.iloc[:, :-1].astype(np.float32))\n",
    "        y_list.append(chunk.iloc[:, -1].astype(np.int32))\n",
    "    \n",
    "    X = pd.concat(X_list, axis=0).values\n",
    "    y = pd.concat(y_list, axis=0).values\n",
    "    \n",
    "    # Split data using index-based split for large datasets\n",
    "    indices = np.arange(len(X))\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        indices, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # StandardScaler with partial_fit for large data\n",
    "    scaler = StandardScaler()\n",
    "    for i in range(0, len(train_idx), chunk_size):\n",
    "        scaler.partial_fit(X[train_idx[i:i+chunk_size]])\n",
    "    \n",
    "    X_train = scaler.transform(X[train_idx])\n",
    "    X_test = scaler.transform(X[test_idx])\n",
    "    \n",
    "    return X_train, X_test, y[train_idx], y[test_idx]\n",
    "\n",
    "# Enhanced Model Architecture with Skip Connections\n",
    "class EEGSeizureNet(nn.Module):\n",
    "    def __init__(self, input_dim=23):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Hidden layer 1\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Hidden layer 2\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Hidden layer 3\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Hidden layer 4\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Hidden layer 5 (reduces to 256 features)\n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        # Apply skip connections for blocks with matching dimensions.\n",
    "        x = x + self.block1(x)\n",
    "        x = x + self.block2(x)\n",
    "        x = x + self.block3(x)\n",
    "        x = x + self.block4(x)\n",
    "        x = self.block5(x)  # Dimension reduces here; skip connection not applied.\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Enhanced Training with Metrics Tracking\n",
    "class Trainer:\n",
    "    def __init__(self, model, device, optimizer, criterion):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.history = {\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_acc': [], 'val_acc': [],\n",
    "            'lr': []\n",
    "        }\n",
    "    \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            inputs = inputs.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True).float().view(-1, 1)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            predicted = (outputs >= 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device).float().view(-1, 1)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                predicted = (outputs >= 0.5).float()\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                all_probs.append(outputs.cpu())\n",
    "                all_labels.append(labels.cpu())\n",
    "                \n",
    "        epoch_loss = running_loss / len(test_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        return epoch_loss, epoch_acc, torch.cat(all_probs), torch.cat(all_labels)\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs=50):\n",
    "        best_acc = 0.0\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = self.train_epoch(train_loader)\n",
    "            val_loss, val_acc, _, _ = self.evaluate(val_loader)\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            self.history['lr'].append(self.optimizer.param_groups[0]['lr'])\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "            print(\"-----------------------------------\")\n",
    "            \n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(self.model.state_dict(), \"best_model.pth\")\n",
    "    \n",
    "    def plot_metrics(self):\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        ax[0].plot(self.history['train_loss'], label='Train Loss')\n",
    "        ax[0].plot(self.history['val_loss'], label='Val Loss')\n",
    "        ax[0].set_title('Loss Curve')\n",
    "        ax[0].legend()\n",
    "        \n",
    "        ax[1].plot(self.history['train_acc'], label='Train Accuracy')\n",
    "        ax[1].plot(self.history['val_acc'], label='Val Accuracy')\n",
    "        ax[1].set_title('Accuracy Curve')\n",
    "        ax[1].legend()\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def plot_confusion_matrix(self, probs, labels, threshold=0.5):\n",
    "        y_pred = (probs >= threshold).numpy()\n",
    "        cm = confusion_matrix(labels.numpy(), y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(6, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                  xticklabels=['No Seizure', 'Seizure'],\n",
    "                  yticklabels=['No Seizure', 'Seizure'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_roc_curve(self, probs, labels):\n",
    "        fpr, tpr, _ = roc_curve(labels.numpy(), probs.numpy())\n",
    "        roc_auc = roc_auc_score(labels.numpy(), probs.numpy())\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "               label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    def full_report(self, test_loader):\n",
    "        _, _, probs, labels = self.evaluate(test_loader)\n",
    "        probs = probs.squeeze()\n",
    "        labels = labels.squeeze()\n",
    "        \n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(labels.numpy(), (probs >= 0.5).numpy(),\n",
    "                                target_names=['No Seizure', 'Seizure']))\n",
    "        \n",
    "        print(f\"ROC AUC Score: {roc_auc_score(labels, probs):.4f}\")\n",
    "        print(f\"Average Precision: {average_precision_score(labels, probs):.4f}\")\n",
    "        \n",
    "        self.plot_confusion_matrix(probs, labels)\n",
    "        self.plot_roc_curve(probs, labels)\n",
    "        self.plot_metrics()\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == '__main__':\n",
    "    # Load data with efficient memory management\n",
    "    X_train, X_test, y_train, y_test = load_data('D:\\\\MOOC.fi\\\\Jupyter\\\\EEG\\\\Dataset\\\\chbmit_preprocessed_data.csv')\n",
    "    \n",
    "    # Create TensorDatasets\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                  torch.tensor(y_train, dtype=torch.float32))\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                                 torch.tensor(y_test, dtype=torch.float32))\n",
    "    \n",
    "    # Create DataLoaders with large batch size\n",
    "    batch_size = 4096  # Adjusted for large dataset\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                            num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                           num_workers=4, pin_memory=True)\n",
    "    \n",
    "    # Initialize model and components\n",
    "    model = EEGSeizureNet(input_dim=X_train.shape[1])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Train model\n",
    "    trainer = Trainer(model, device, optimizer, criterion)\n",
    "    trainer.train(train_loader, test_loader, epochs=40)\n",
    "    \n",
    "    # Generate full performance report\n",
    "    trainer.full_report(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c729225-9e27-477c-9095-d518629da902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
