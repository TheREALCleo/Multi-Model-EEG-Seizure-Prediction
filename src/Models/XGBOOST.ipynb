{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c6e9db-e247-4f72-a95c-4dedadf2ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report,\n",
    "                             ConfusionMatrixDisplay, roc_curve, auc)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97333752-3cab-437d-b6cb-6e5eed10cbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after shuffling:\n",
      "target\n",
      "1    0.500061\n",
      "0    0.499939\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load and shuffle data to prevent ordered outcomes\n",
    "data = pd.read_csv('D:\\\\MOOC.fi\\\\Jupyter\\\\EEG\\\\Dataset\\\\timefeature_data_final.csv')\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)  # Critical shuffle\n",
    "\n",
    "# Verify class distribution after shuffling\n",
    "print(\"Class distribution after shuffling:\")\n",
    "print(data['target'].value_counts(normalize=True))\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fedb4d7-578a-40cd-a279-15c2251360b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 10484, Val size: 2621, Test size: 3277\n"
     ]
    }
   ],
   "source": [
    "# First split: 80% train-val, 20% test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create validation set from trainval for early stopping\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval,\n",
    "    test_size=0.2,\n",
    "    stratify=y_trainval,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Val size: {len(X_val)}, Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccce6c99-3aba-4cf7-9171-058bc29f31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weight for imbalance handling\n",
    "class_weight = len(y_train[y_train==0]) / len(y_train[y_train==1])\n",
    "\n",
    "# Configure pipeline with proper data flow\n",
    "pipeline = Pipeline([\n",
    "    ('xgb', xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=1000,\n",
    "        early_stopping_rounds=50,\n",
    "        random_state=42,\n",
    "        tree_method='hist',\n",
    "        device='cuda'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Enhanced parameter grid\n",
    "param_grid = {\n",
    "    'xgb__learning_rate': [0.01, 0.05],\n",
    "    'xgb__max_depth': [3, 5, 7],\n",
    "    'xgb__subsample': [0.6, 0.8],\n",
    "    'xgb__colsample_bytree': [0.6, 0.8],\n",
    "    'xgb__gamma': [0, 0.1],\n",
    "    'xgb__reg_alpha': [0, 0.1],\n",
    "    'xgb__reg_lambda': [0, 0.1],\n",
    "    'xgb__scale_pos_weight': [1, class_weight]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f16c48-7fc4-49df-94fe-2c3a3716b643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 384 candidates, totalling 1152 fits\n"
     ]
    }
   ],
   "source": [
    "# Configure grid search with inner CV\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=inner_cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "# Fit with validation set for early stopping\n",
    "grid_search.fit(\n",
    "    X_train, y_train,\n",
    "    xgb__eval_set=[(X_val, y_val)]\n",
    ")\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552f80a-f7ba-40ba-9006-db6f714b98ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"\\n=== Final Test Set Performance ===\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap='Blues')\n",
    "    plt.title('Test Set Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.title('Test Set ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return y_proba\n",
    "\n",
    "y_proba = evaluate_model(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bff24a-5faf-4844-8d97-6e7fe7f603a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model):\n",
    "    # Access scaler from pipeline\n",
    "    scaled_features = model.named_steps['scaler'].get_feature_names_out(X.columns)\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = model.named_steps['xgb'].feature_importances_\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': scaled_features,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(importance_df['Feature'][:20], importance_df['Importance'][:20])\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.xlabel('Gain Importance')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "def shap_analysis(model, X_sample):\n",
    "    # Process sample data through pipeline steps\n",
    "    scaled_data = model.named_steps['scaler'].transform(X_sample)\n",
    "    \n",
    "    explainer = shap.TreeExplainer(model.named_steps['xgb'])\n",
    "    shap_values = explainer.shap_values(scaled_data)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, scaled_data, feature_names=X.columns, show=False)\n",
    "    plt.title('SHAP Value Distribution')\n",
    "    plt.show()\n",
    "\n",
    "# Use subset for SHAP analysis\n",
    "shap_sample = X_test.sample(n=500, random_state=42)\n",
    "shap_analysis(best_model, shap_sample)\n",
    "plot_feature_importance(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082fbd6-31fd-447d-ad79-5e3133ccedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model):\n",
    "    results = model.named_steps['xgb'].evals_result()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(results['validation_0']['logloss'], label='Validation Loss')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Log Loss')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curve(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09dc3aa-a881-40f5-97af-38122467f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Optimal Parameters ===\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Retrain on combined train-val data\n",
    "final_model = grid_search.best_estimator_.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9236abe-f4ee-4f50-b620-7c93a93faaa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c571d3c8-3050-4b3e-be8a-e9d7e5ebdaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
